<!-- docs/math/03-limited-search.html -->
<section class="chapter" id="03-limited-search">
    <h2 id="3-limited-search">3. <ruby>限定的探索<rt>げんていてきたんさく</rt></ruby></h2>
    <div class="para">
        推論規則による<ruby>縮約<rt>しゅくやく</rt></ruby>を繰り返してもなお盤面が完全に決定しない場合、探索が不可避となる。ここでいう探索とは、あるセルに仮置きを行い、その後の帰結を逐次検証しながら<ruby>分岐<rt>ぶんき</rt></ruby>と<ruby>バックトラック<rt>backtrack</rt></ruby>を行う過程を指す。探索空間の理論的上界は $9^{81} \approx 10^{77}$ 通りに及ぶため、無作為な試行は現実的ではない。したがって探索効率の鍵は「どのセルを分岐点に選ぶか」にある。

        基本的かつ有効な戦略として Minimum Remaining Value (MRV) ヒューリスティクスが知られている。これは候補数が最小のセルを優先的に選択するものであり、早期に矛盾を露呈させて探索木の枝を<ruby>剪定<rt>せんてい</rt></ruby>できる効果を持つ。形式的には「最も制約の強い変数から試す」という原則に対応し、制約伝播を強力に補完する。実際に MRV を用いない場合の探索木の平均分岐数は 5 前後に達するが、MRV を導入することで 2〜3 程度まで減少することが経験的に報告されている。候補数が等しいセルが複数存在する場合には、セルが属する行・列・ブロックにおける未確定セル数が多いものを選択する Degree ヒューリスティクス を組み合わせることが効果的である。これは「最も他に影響を及ぼす変数」を優先する戦略であり、探索効率をさらに高める。より洗練された基準として、情報理論的な指標であるエントロピーを導入することができる。変数 $v$ に候補集合 $D(v)$ が割り当てられているとし、各候補値 $d \in D(v)$ に確率 $p_d$ が割り当てられるとき、その不確実性は

        $$H(v) = -\sum_{d \in D(v)} p_d \log p_d$$

        によって測定される。エントロピー $H(v)$ が小さいセルを分岐点として選択することは、探索によって不確実性を最も削減できる箇所を優先することに対応する。確率 $p_d$ の設定方法としては、単純に一様分布 $p_d = \frac{1}{|D(v)|}$ を仮定する場合のほか、制約伝播の頻度や過去の探索履歴に基づいて統計的に推定する方法も考えられる。このアプローチは<ruby>確率的制約充足問題<rt>かくりつてきせいやくじゅうそくもんだい</rt></ruby>やベイズ的最適化との関連を持ち、数独を超えて汎用的な探索戦略への接続を可能にする。探索過程における失敗は単なる後戻りにとどまらない。ある仮置きの下で矛盾が生じた場合、その矛盾は具体的な候補集合に関する「ノーグッド (nogood)」として記録され、以降の探索で再利用される。これが<ruby>失敗駆動学習<rt>しっぱいくどうがくしゅう</rt></ruby> (failure-driven learning) の基本理念である。形式的には、探索におけるノーグッド集合は $\Sigma$ 上の禁止領域を逐次拡張する過程とみなすことができ、これは SAT ソルバにおける<ruby>節学習<rt>せつがくしゅう</rt></ruby> (clause learning) と構造的に同型である。すなわち、局所的な矛盾情報を全体に伝播させることによって、探索の重複計算を回避しつつ<ruby>健全性<rt>けんぜんせい</rt></ruby>を保持することが可能となる。このように限定的探索は、単なる力任せの試行錯誤ではなく、ヒューリスティクスと学習機構を統合した体系的な推論過程である。推論規則による候補削減と探索ヒューリスティクスによる分岐選択とを組み合わせることで、数独の解読は実用的時間内に遂行可能となり、同時に制約充足問題における一般的探索戦略の理論的研究に対しても重要な示唆を与えるのである。
    </div>
</section>