<!-- docs/math/10-complexity-optimization.html -->
<section class="chapter" id="10-complexity-optimization">
    <h2 id="10-complexity-optimization">10. 複雑性の分析と最適化</h2>
    <div class="para">
        数独解読の計算複雑性を評価する場合、探索アルゴリズムの理論的計算量は本質的に指数時間であることを免れない。これは制約充足問題一般における NP 完全性の帰結であり、最悪の場合には $9^{81}$ に近い組合せ的爆発が潜在する。しかし実際の解読過程では、各セルの候補集合に対する縮約規則の反復適用が大部分の変数を初期段階で確定させるため、探索空間は指数的増大の可能性を持ちながらも実効的には劇的に縮小する。したがって平均的な実行時間は盤面の構造、初期与え値の配置、難易度に密接に依存し、単なる理論的上界では予測できない振る舞いを示す。この複雑性を実用的水準に抑制するための第一要素はデータ構造の選択である。各セルの候補集合を $9$ ビットのマスクとして表現するならば、候補削減や確定判定の演算は単一のビット演算すなわち定数時間で遂行可能となる。さらに盤面全体にわたる候補更新処理も $81$ セルに対する走査で完結するため $O(81)$、すなわち定数時間に等しい計算で済む。この手法は高水準言語である Python 実装においても十分高速に動作し、C 言語や Cython による低レベル最適化を導入すれば一桁から二桁の性能向上が期待される。探索の複雑性削減においてはヒューリスティクスの設計が決定的である。最小残余値 (MRV: Minimum Remaining Values) に基づく分岐点選択は探索木の平均深度を効果的に抑制し、分岐ごとの期待情報量を指標として採用すればさらに効率的な枝刈りが可能となる。加えて失敗駆動学習によるノーグッド集合の共有は SAT ソルバにおける conflict-driven clause learning (CDCL) の技術を応用するものであり、探索木における重複経路を劇的に排除する。この結果、理論的には指数的な探索であっても、実際の平均的複雑性は多項式的に近似可能な水準まで低減されることが多い。以上のように数独解読における効率性は、形式的な計算量解析と経験的な平均挙動の差異を正しく理解した上で、適切なデータ構造とヒューリスティクスを選択することによって初めて最適化される。理論的複雑性の峻厳さを認めつつも、実装工学的工夫により実効的な高速解読を実現することこそが、数独ソルバ設計の核心である。
    </div>
</section>